MLC_LLM_ENGINE_MODE = server
MLC_LLM_MAX_BATCH_SIZE = 80
MLC_LLM_MAX_KV_CACHE_SIZE = 32768


ROUNDS=1

MODEL_AGGREGATE=HF://mlc-ai/Hermes-2-Theta-Llama-3-8B-q0f16_1-MLC
MODEL_REFERENCE_1=HF://mlc-ai/Mistral-7B-Instruct-v0.3-q0f16_1-MLC
MODEL_REFERENCE_2=HF://mlc-ai/Phi-3-mini-128k-instruct-q0f16_1-MLC
MODEL_REFERENCE_3=HF://mlc-ai/Mixtral-8x7B-Instruct-v0.1-q0f16_1-MLC

MULTITURN=True
